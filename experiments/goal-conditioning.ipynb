{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal-oriented self-improvement for Automated Theorem Proving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method\n",
    "We are basically thinking of extending minimo by introducing a goal i.e. a set of problems the model should eventually solve. We do this by adding loss-term forcing the model to sample conjectures from our goal set. We control this ‘forcing’ using a hyperparameter `alpha`. A higher value gives the `progess_loss` more value, thus pushes the model towards the goal stronger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "environment\t  launch    pyproject.toml\t     slurm-1275749.out\n",
      "experiments\t  learning  README.md\t\t     slurm-1275750.out\n",
      "FAQ.md\t\t  LICENSE   redis_hostname_port.txt  slurm-1275751.out\n",
      "goals\t\t  logs\t    setup.sh\t\t     tutorial.md\n",
      "install_redis.sh  outputs   slurm-1275748.out\t     wandb\n"
     ]
    }
   ],
   "source": [
    "# lets move to the parent directory so it is easier to run the scripts\n",
    "import os\n",
    "\n",
    "if os.getcwd().split('/')[-1] == 'experiments':\n",
    "    os.chdir('../')\n",
    "\n",
    "!ls\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the now we use a very simple goal set. It consists of a single goal which is proving the theorem: \n",
    "\n",
    "`(1 + a0) + a1 = 1 + (a0 + a1)`\n",
    "\n",
    "Or in peano:\n",
    "\n",
    "`[('a0 : nat) -> ('a1 : nat) -> (= (+ (s 'a0) 'a1) (s (+ 'a0 'a1)))]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Overfit on the goal set\n",
    "After implementing the goal-conditioning, let's run experiments with `alpha=0` and `alpha=1`. We expect the `progress_loss` to go down i.e. the model overfits to the `final_goal` set. However, the actual `train_loss` shouldn’t go down. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 1275755\n"
     ]
    }
   ],
   "source": [
    "# start a job with alpha=0 as a baseline\n",
    "!sbatch --job-name=train_alpha_0 --cpus-per-task=4 --mem=50G --gres=gpu:1,VRAM=12G --time=24:00:00 --wrap=\"python learning/bootstrap.py theory=nat-add alpha=0\"\n",
    "\n",
    "# start a job with alpha=1 to overfit on the goals\n",
    "# !sbatch --job-name=train_alpha_1 --cpus-per-task=4 --mem=50G --gres=gpu:1,VRAM=12G --time=24:00:00 --wrap=\"python learning/bootstrap.py theory=nat-add alpha=1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Works! The ``training_loss`` diverges for `alpha=1`. The `progress_loss` struggles to go below a certain threshold for `alpha=0`. Interestingly, the former overfits to sampling the final theorem and can't solve any conjectures in the second iteration. We need something better for alpha."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Try different values for alpha\n",
    "\n",
    "We try different schedules for alpha in the hope that the training loss and progress loss both converge. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 1275099\n"
     ]
    }
   ],
   "source": [
    "# !sbatch --job-name=train_alpha_0_8 --cpus-per-task=4 --mem=50G --gres=gpu:1,VRAM=12G --time=24:00:00 --wrap=\"python learning/bootstrap.py theory=nat-add alpha=0.8\"\n",
    "\n",
    "# !sbatch --job-name=train_alpha_0_6 --cpus-per-task=4 --mem=50G --gres=gpu:1,VRAM=12G --time=24:00:00 --wrap=\"python learning/bootstrap.py theory=nat-add alpha=0.6\"\n",
    "\n",
    "# !sbatch --job-name=train_alpha_0_4 --cpus-per-task=4 --mem=50G --gres=gpu:1,VRAM=12G --time=24:00:00 --wrap=\"python learning/bootstrap.py theory=nat-add alpha=0.4\"\n",
    "\n",
    "# !sbatch --job-name=train_alpha_0_2 --cpus-per-task=4 --mem=50G --gres=gpu:1,VRAM=12G --time=24:00:00 --wrap=\"python learning/bootstrap.py theory=nat-add alpha=0.2\"\n",
    "\n",
    "# !sbatch --job-name=train_alpha_0_3e_4 --cpus-per-task=4 --mem=50G --gres=gpu:1,VRAM=12G --time=24:00:00 --wrap=\"python learning/bootstrap.py theory=nat-add alpha=3e-4\"\n",
    "\n",
    "!sbatch --job-name=train_alpha_0_1e_3 --cpus-per-task=4 --mem=50G --gres=gpu:1,VRAM=12G --time=24:00:00 --wrap=\"python learning/bootstrap.py theory=nat-add alpha=1e-3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works as well. We also observe a correlation between alpha values and the ratio of conjectures that the model is able to prove per iteration. The higher the alpha value, the fewer problems the model can solve. What if we could let the model explore problems for itself for a while and at a later stage push it towards our goal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Alpha Schedules\n",
    "\n",
    "We implement fancy schedules to 'warm-up' alpha over several iterations. The options are \n",
    "\n",
    "`alpha_schedule = [ constant | linear | quadratic | cubic | cos ]`\n",
    "\n",
    "#### 3.1 Warm up alpha to 1.0\n",
    "\n",
    "As a first step we warm up alpha to 1.0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 1274969\n"
     ]
    }
   ],
   "source": [
    "#!sbatch --job-name=train_alpha_lin --cpus-per-task=4 --mem=50G --gres=gpu:1,VRAM=12G --time=10:00:00 --wrap=\"python learning/bootstrap.py theory=nat-add alpha=1 alpha_schedule=linear\"\n",
    "\n",
    "#!sbatch --job-name=train_alpha_quad --cpus-per-task=4 --mem=50G --gres=gpu:1,VRAM=12G --time=10:00:00 --wrap=\"python learning/bootstrap.py theory=nat-add alpha=1 alpha_schedule=quadratic\"\n",
    "\n",
    "!sbatch --job-name=train_alpha_cubic --cpus-per-task=4 --mem=50G --gres=gpu:1,VRAM=12G --time=10:00:00 --wrap=\"python learning/bootstrap.py theory=nat-add alpha=1 alpha_schedule=cubic\"\n",
    "\n",
    "# !sbatch --job-name=train_alpha_cos --cpus-per-task=4 --mem=50G --gres=gpu:1,VRAM=12G --time=10:00:00 --wrap=\"python learning/bootstrap.py theory=nat-add alpha=1 alpha_schedule=cos\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is apparent that high values of alpha just overpower the actual loss. Ideally we wan't to keep alpha much smaller. Let's try just warming it up to lower values. \n",
    "\n",
    "#### 3.2 Warm up alpha to lower values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 1274557\n",
      "Submitted batch job 1274558\n",
      "Submitted batch job 1274559\n"
     ]
    }
   ],
   "source": [
    "!sbatch --job-name=train_alpha_cubic --cpus-per-task=4 --mem=50G --gres=gpu:1,VRAM=12G --time=10:00:00 --wrap=\"python learning/bootstrap.py theory=nat-add alpha=0.2 alpha_schedule=cubic\"\n",
    "\n",
    "!sbatch --job-name=train_alpha_cubic --cpus-per-task=4 --mem=50G --gres=gpu:1,VRAM=12G --time=10:00:00 --wrap=\"python learning/bootstrap.py theory=nat-add alpha=0.3 alpha_schedule=cubic\"\n",
    "\n",
    "!sbatch --job-name=train_alpha_cubic --cpus-per-task=4 --mem=50G --gres=gpu:1,VRAM=12G --time=10:00:00 --wrap=\"python learning/bootstrap.py theory=nat-add alpha=0.4 alpha_schedule=cubic\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Use the ratio of solved conjectures \n",
    "We use the ratio of solved conjectures to total sampled conjectures to directly control alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 1274560\n",
      "Submitted batch job 1274561\n"
     ]
    }
   ],
   "source": [
    "!sbatch --job-name=train_alpha_ratio --cpus-per-task=4 --mem=50G --gres=gpu:1,VRAM=12G --time=10:00:00 --wrap=\"python learning/bootstrap.py theory=nat-add alpha=1 alpha_schedule=ratio\"\n",
    "\n",
    "!sbatch --job-name=train_alpha_ratio --cpus-per-task=4 --mem=50G --gres=gpu:1,VRAM=12G --time=10:00:00 --wrap=\"python learning/bootstrap.py theory=nat-add alpha=0.2 alpha_schedule=ratio\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Increase max iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 1275039\n",
      "Submitted batch job 1275040\n",
      "Submitted batch job 1275041\n"
     ]
    }
   ],
   "source": [
    "!sbatch --job-name=train_alpha_long --cpus-per-task=4 --mem=50G --gres=gpu:1,VRAM=12G --time=20:00:00 --wrap=\"python learning/bootstrap.py theory=nat-add alpha=0 iterations=30\"\n",
    "\n",
    "!sbatch --job-name=train_alpha_long_ratio --cpus-per-task=4 --mem=50G --gres=gpu:1,VRAM=12G --time=20:00:00 --wrap=\"python learning/bootstrap.py theory=nat-add alpha=1 alpha_schedule=ratio iterations=30\"\n",
    "\n",
    "!sbatch --job-name=train_alpha_long_cos --cpus-per-task=4 --mem=50G --gres=gpu:1,VRAM=12G --time=20:00:00 --wrap=\"python learning/bootstrap.py theory=nat-add alpha=1 alpha_schedule=cubic iterations=30\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minimo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
