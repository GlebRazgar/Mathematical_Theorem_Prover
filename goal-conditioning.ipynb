{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal-oriented self-improvement for Automated Theorem Proving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method\n",
    "We are basically thinking of extending minimo by introducing a goal i.e. a set of problems the model should eventually solve. We do this by adding loss-term forcing the model to sample conjectures from our goal set. We control this ‘forcing’ using a hyperparameter `alpha`. A higher value gives the `progess_loss` more value, thus pushes the model towards the goal stronger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the now we use a very simple goal set. It consists of a single goal which is proving the theorem: \n",
    "\n",
    "`(1 + a0) + a1 = 1 + (a0 + a1)`\n",
    "\n",
    "Or in peano:\n",
    "\n",
    "`[('a0 : nat) -> ('a1 : nat) -> (= (+ (s 'a0) 'a1) (s (+ 'a0 'a1)))]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Overfit on the goal set\n",
    "After implementing the goal-conditioning, let's run experiments with `alpha=0` and `alpha=1`. We expect the `progress_loss` to go down i.e. the model overfits to the `final_goal` set. However, the actual `train_loss` shouldn’t go down. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 1274470\n",
      "Submitted batch job 1274471\n"
     ]
    }
   ],
   "source": [
    "# start a job with alpha=0 as a baseline\n",
    "!sbatch --job-name=train_alpha_0 --cpus-per-task=4 --mem=50G --gres=gpu:1,VRAM=12G --time=24:00:00 --wrap=\"python learning/bootstrap.py theory=nat-add alpha=0\"\n",
    "\n",
    "# start a job with alpha=1 to overfit on the goals\n",
    "!sbatch --job-name=train_alpha_1 --cpus-per-task=4 --mem=50G --gres=gpu:1,VRAM=12G --time=24:00:00 --wrap=\"python learning/bootstrap.py theory=nat-add alpha=1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Works! The ``training_loss`` diverges for `alpha=1`. The `progress_loss` struggles to go below a certain threshold for `alpha=0`. Interestingly, the former overfits to sampling the final theorem and can't solve any conjectures in the second iteration. We need something smarter for alpha."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Try different values for alpha\n",
    "\n",
    "We try different schedules for alpha in the hope that the training loss and progress loss both converge. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 1274473\n",
      "Submitted batch job 1274474\n",
      "Submitted batch job 1274475\n",
      "Submitted batch job 1274476\n"
     ]
    }
   ],
   "source": [
    "!sbatch --job-name=train_alpha_0_8 --cpus-per-task=4 --mem=50G --gres=gpu:1,VRAM=12G --time=24:00:00 --wrap=\"python learning/bootstrap.py theory=nat-add alpha=0.8\"\n",
    "\n",
    "!sbatch --job-name=train_alpha_0_6 --cpus-per-task=4 --mem=50G --gres=gpu:1,VRAM=12G --time=24:00:00 --wrap=\"python learning/bootstrap.py theory=nat-add alpha=0.6\"\n",
    "\n",
    "!sbatch --job-name=train_alpha_0_4 --cpus-per-task=4 --mem=50G --gres=gpu:1,VRAM=12G --time=24:00:00 --wrap=\"python learning/bootstrap.py theory=nat-add alpha=0.4\"\n",
    "\n",
    "!sbatch --job-name=train_alpha_0_2 --cpus-per-task=4 --mem=50G --gres=gpu:1,VRAM=12G --time=24:00:00 --wrap=\"python learning/bootstrap.py theory=nat-add alpha=0.2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works as well. We also observe a correlation between alpha values and the ratio of conjectures that the model is able to prove per iteration. The higher the alpha value, the fewer problems the model can solve. What if we could let the model explore problems for itself for a while and at a later stage push it towards our goal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Alpha Schedules\n",
    "\n",
    "We implement fancy schedules to 'warm-up' alpha over several iterations. The options are \n",
    "\n",
    "`alpha_schedule = [ constant | linear | quadratic | cubic ]`\n",
    "\n",
    "#### 3.1 Warm up alpha to 1.0\n",
    "\n",
    "As a first step we warm up alpha to 1.0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !sbatch --job-name=train_alpha_lin --cpus-per-task=4 --mem=50G --gres=gpu:1,VRAM=12G --time=10:00:00 --wrap=\"python learning/bootstrap.py theory=nat-add alpha=1 alpha_schedule=linear\"\n",
    "\n",
    "!sbatch --job-name=train_alpha_quad --cpus-per-task=4 --mem=50G --gres=gpu:1,VRAM=12G --time=10:00:00 --wrap=\"python learning/bootstrap.py theory=nat-add alpha=1 alpha_schedule=quadratic\"\n",
    "\n",
    "!sbatch --job-name=train_alpha_cubic --cpus-per-task=4 --mem=50G --gres=gpu:1,VRAM=12G --time=10:00:00 --wrap=\"python learning/bootstrap.py theory=nat-add alpha=1 alpha_schedule=cubic\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minimo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
